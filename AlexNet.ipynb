{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arjavjain100/Apple-Scab-Detection/blob/main/AlexNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIcgjnzepVAT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as opt\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLB9W7cLp6DQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),\n",
        "            nn.BatchNorm2d(96),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2, padding=0))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(384),\n",
        "            nn.ReLU())\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(384),\n",
        "            nn.ReLU())\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(9216, 4096),\n",
        "            nn.ReLU())\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU())\n",
        "        self.fc2= nn.Sequential(\n",
        "            nn.Linear(4096, num_classes))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        out = self.layer1(x)\n",
        "        # print(out.shape)\n",
        "        out = self.layer2(out)\n",
        "        # print(out.shape)\n",
        "        out = self.layer3(out)\n",
        "        # print(out.shape)\n",
        "        out = self.layer4(out)\n",
        "        # print(out.shape)\n",
        "        out = self.layer5(out)\n",
        "        # print(out.shape)\n",
        "        out = torch.flatten(out, start_dim =1)\n",
        "        # print(out.shape)\n",
        "        out = self.fc(out)\n",
        "        # print(out.shape)\n",
        "        out = self.fc1(out)\n",
        "        # print(out.shape)\n",
        "        out = self.fc2(out)\n",
        "        # print(out.shape)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kp200KbN1Fry"
      },
      "outputs": [],
      "source": [
        "def train(model, epochs, criterion, optimizer, trainloader, testloader, device):\n",
        "  \n",
        "  total_step = len(trainloader)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      for i, (images, labels) in enumerate(trainloader):  \n",
        "          # Move tensors to the configured device\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "          \n",
        "          # Forward pass\n",
        "          outputs = model(images)\n",
        "          loss = criterion(outputs, labels)\n",
        "          \n",
        "          # Backward and optimize\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "      print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                    .format(epoch+1, epochs, i+1, total_step, loss.item()))\n",
        "              \n",
        "      # Validation\n",
        "      with torch.no_grad():\n",
        "          correct = 0\n",
        "          total = 0\n",
        "          for images, labels in testloader:\n",
        "              images = images.to(device)\n",
        "              labels = labels.to(device)\n",
        "              outputs = model(images)\n",
        "              _, predicted = torch.max(outputs.data, 1)\n",
        "              total += labels.size(0)\n",
        "              correct += (predicted == labels).sum().item()\n",
        "              del images, labels, outputs\n",
        "      \n",
        "          print('Validation Accuracy: {} %'.format(100 * correct / total)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywOkNd3bwBdp",
        "outputId": "39e2b34b-05d0-496c-fb99-932899d7c6a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZZ4MNbbUzSS",
        "outputId": "34560205-b82e-4bf9-9250-f8bd7d4757a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (layer1): Sequential(\n",
              "    (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
              "    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (layer5): Sequential(\n",
              "    (0): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (fc1): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (fc2): Sequential(\n",
              "    (0): Linear(in_features=4096, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = AlexNet(2)\n",
        "optimizer = opt.SGD(model.parameters(),lr=0.0005)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "model = model.to(device)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DyqG2K8SWQ3t"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "\n",
        "transform = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize((227, 227)),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225])]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize((227, 227)),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225])])\n",
        "}\n",
        "test_data = datasets.ImageFolder('/content/drive/MyDrive/Minor Project 1/Test', transform = transform['test'])\n",
        "train_data = datasets.ImageFolder('/content/drive/MyDrive/Minor Project 1/Train',  transform = transform['train'])\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_data, shuffle=True, batch_size=batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_data, shuffle=True, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSTJcaMVVomy",
        "outputId": "1e40896f-650a-4dd9-ac23-d8ef4920b144"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Step [17/17], Loss: 0.7557\n",
            "Validation Accuracy: 32.432432432432435 %\n",
            "Epoch [2/20], Step [17/17], Loss: 0.7891\n",
            "Validation Accuracy: 32.432432432432435 %\n",
            "Epoch [3/20], Step [17/17], Loss: 0.2939\n",
            "Validation Accuracy: 32.432432432432435 %\n",
            "Epoch [4/20], Step [17/17], Loss: 0.5650\n",
            "Validation Accuracy: 32.432432432432435 %\n",
            "Epoch [5/20], Step [17/17], Loss: 0.2256\n",
            "Validation Accuracy: 32.432432432432435 %\n",
            "Epoch [6/20], Step [17/17], Loss: 0.5747\n",
            "Validation Accuracy: 32.432432432432435 %\n",
            "Epoch [7/20], Step [17/17], Loss: 0.7961\n",
            "Validation Accuracy: 29.72972972972973 %\n",
            "Epoch [8/20], Step [17/17], Loss: 0.2744\n",
            "Validation Accuracy: 32.432432432432435 %\n",
            "Epoch [9/20], Step [17/17], Loss: 0.2909\n",
            "Validation Accuracy: 32.432432432432435 %\n",
            "Epoch [10/20], Step [17/17], Loss: 0.4082\n",
            "Validation Accuracy: 32.432432432432435 %\n",
            "Epoch [11/20], Step [17/17], Loss: 0.6274\n",
            "Validation Accuracy: 32.432432432432435 %\n",
            "Epoch [12/20], Step [17/17], Loss: 0.6891\n",
            "Validation Accuracy: 32.432432432432435 %\n",
            "Epoch [13/20], Step [17/17], Loss: 0.4530\n",
            "Validation Accuracy: 32.432432432432435 %\n",
            "Epoch [14/20], Step [17/17], Loss: 0.3383\n",
            "Validation Accuracy: 32.432432432432435 %\n",
            "Epoch [15/20], Step [17/17], Loss: 0.9966\n",
            "Validation Accuracy: 27.027027027027028 %\n",
            "Epoch [16/20], Step [17/17], Loss: 0.6257\n",
            "Validation Accuracy: 27.027027027027028 %\n",
            "Epoch [17/20], Step [17/17], Loss: 0.2598\n",
            "Validation Accuracy: 32.432432432432435 %\n",
            "Epoch [18/20], Step [17/17], Loss: 0.2970\n",
            "Validation Accuracy: 24.324324324324323 %\n",
            "Epoch [19/20], Step [17/17], Loss: 0.4667\n",
            "Validation Accuracy: 32.432432432432435 %\n",
            "Epoch [20/20], Step [17/17], Loss: 0.2760\n",
            "Validation Accuracy: 29.72972972972973 %\n"
          ]
        }
      ],
      "source": [
        "train(model, 20 , criterion, optimizer, train_loader, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9vM_fsKZtof"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "mount_file_id": "1KQrpj8-JNkHPId-bRg7sWWHksjcNB4Xu",
      "authorship_tag": "ABX9TyMa2UVNBt8ikvjSSADPKNpd",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}